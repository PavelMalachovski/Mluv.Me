"""
–õ–∏—á–Ω–æ—Å—Ç—å –•–æ–Ω–∑–∏–∫–∞ - –≤–µ—Å–µ–ª–æ–≥–æ —Ç–∏–ø–∏—á–Ω–æ–≥–æ —á–µ—Ö–∞, –ø–æ–º–æ–≥–∞—é—â–µ–≥–æ —É—á–∏—Ç—å —á–µ—à—Å–∫–∏–π —è–∑—ã–∫.

–†–µ–∞–ª–∏–∑—É–µ—Ç:
- –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–æ–º –•–æ–Ω–∑–∏–∫–∞
- 3 —Å—Ç–∏–ª—è –æ–±—â–µ–Ω–∏—è (Friendly, Tutor, Casual)
- 3 —É—Ä–æ–≤–Ω—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π (Minimal, Balanced, Detailed)
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –∏ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
- –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π)
"""

import json
from functools import lru_cache
from typing import Literal

import structlog

from backend.services.openai_client import OpenAIClient
from backend.services.cache_service import cache_service
from backend.services.model_selector import model_selector

logger = structlog.get_logger(__name__)

# –¢–∏–ø—ã –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
ConversationStyle = Literal["friendly", "tutor", "casual"]
CorrectionsLevel = Literal["minimal", "balanced", "detailed"]
CzechLevel = Literal["beginner", "intermediate", "advanced", "native"]
NativeLanguage = Literal["ru", "uk", "pl", "sk"]


class HonzikPersonality:
    """
    –õ–∏—á–Ω–æ—Å—Ç—å –•–æ–Ω–∑–∏–∫–∞ - –≤–µ—Å–µ–ª–æ–≥–æ —á–µ—Ö–∞, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —É—á–∏—Ç—å —á–µ—à—Å–∫–∏–π.

    Attributes:
        openai_client: –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API
    """

    def __init__(self, openai_client: OpenAIClient):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏ –•–æ–Ω–∑–∏–∫–∞.

        Args:
            openai_client: –ö–ª–∏–µ–Ω—Ç OpenAI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤
        """
        self.openai_client = openai_client
        self.logger = logger.bind(service="honzik_personality")

    @staticmethod
    @lru_cache(maxsize=64)
    def _get_base_prompt(
        level: CzechLevel,
        corrections_level: CorrectionsLevel,
        native_language: NativeLanguage,
        style: ConversationStyle,
    ) -> str:
        """
        –ü–æ–ª—É—á–∏—Ç—å –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –•–æ–Ω–∑–∏–∫–∞ —Å —É—á—ë—Ç–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

        –ù–æ–≤–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è: –ø–æ–ª–Ω–æ–µ –ø–æ–≥—Ä—É–∂–µ–Ω–∏–µ –≤ —á–µ—à—Å–∫–∏–π —è–∑—ã–∫.
        - –í–µ—Å—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –Ω–∞ —á–µ—à—Å–∫–æ–º
        - –û–±—ä—è—Å–Ω–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–º —á–µ—à—Å–∫–æ–º + –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä–æ–¥–Ω–æ–π —è–∑—ã–∫

        Args:
            level: –£—Ä–æ–≤–µ–Ω—å —á–µ—à—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞
            corrections_level: –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
            native_language: –†–æ–¥–Ω–æ–π —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π)
            style: –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –•–æ–Ω–∑–∏–∫–∞

        Returns:
            str: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è GPT
        """
        # –û–ø–∏—Å–∞–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –Ω–∞ —á–µ—à—Å–∫–æ–º —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Å–ª–æ–≤–∞—Ä–Ω–æ–≥–æ –∑–∞–ø–∞—Å–∞
        level_descriptions = {
            "beginner": "Zaƒç√°teƒçn√≠k (A2-B1) - uƒç√≠ se z√°klady. Pou≈æ√≠vej jednoduch√° slova a fr√°ze z √∫rovnƒõ A2-B1. "
                       "Vyhni se slo≈æit√Ωm v√Ωraz≈Øm a odborn√Ωm term√≠n≈Øm. Mluv jednodu≈°e a jasnƒõ.",
            "intermediate": "St≈ôednƒõ pokroƒçil√Ω (B1-B2) - u≈æ rozum√≠ z√°klad≈Øm. Pou≈æ√≠vej slova z √∫rovnƒõ B1-B2. "
                          "M≈Ø≈æe≈° pou≈æ√≠t bƒõ≈æn√© idiomy a slo≈æitƒõj≈°√≠ gramatick√© struktury.",
            "advanced": "Pokroƒçil√Ω (B2-C1) - mluv√≠ dob≈ôe, pot≈ôebuje praxi. Pou≈æ√≠vej pokroƒçilou slovn√≠ z√°sobu z √∫rovnƒõ B2-C1. "
                       "M≈Ø≈æe≈° pou≈æ√≠vat slo≈æitƒõj≈°√≠ v√Ωrazy, idiomy a odborn√© term√≠ny.",
            "native": "Rodil√Ω mluvƒç√≠ (C2) - perfekcionismus. Pou≈æ√≠vej nejpokroƒçilej≈°√≠ slovn√≠ z√°sobu na √∫rovni C2. "
                     "M≈Ø≈æe≈° pou≈æ√≠vat v≈°echny jazykov√© prost≈ôedky vƒçetnƒõ slo≈æit√Ωch idiom≈Ø a odborn√Ωch term√≠n≈Ø.",
        }

        # –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∏–ª–µ–π –æ–±—â–µ–Ω–∏—è —Å –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º –æ –ø–æ—Å—Ç–æ—è–Ω—Å—Ç–≤–µ
        style_descriptions = {
            "friendly": "Buƒè p≈ô√°telsk√Ω a povzbuzuj√≠c√≠. Minimum technick√Ωch vysvƒõtlen√≠, "
                       "maximum pozitivity. Pokraƒçuj v konverzaci p≈ôirozenƒõ. "
                       "D≈ÆLE≈ΩIT√â: V≈ædy dodr≈æuj tento styl - NEMƒö≈á ho bƒõhem konverzace!",
            "tutor": "Buƒè jako uƒçitel - strukturovan√© rady, vysvƒõtlen√≠ gramatick√Ωch pravidel, "
                    "doporuƒçen√≠ pro v√Ωslovnost. V√≠ce technick√Ωch detail≈Ø. "
                    "D≈ÆLE≈ΩIT√â: V≈ædy dodr≈æuj tento styl - NEMƒö≈á ho bƒõhem konverzace!",
            "casual": "Buƒè neform√°ln√≠ jako kamar√°d v hospodƒõ. Minimum oprav (jen kritick√©), "
                     "maximum legrace a p≈ôirozen√© konverzace. Mluv o pivu a klob√°sk√°ch! "
                     "D≈ÆLE≈ΩIT√â: V≈ædy dodr≈æuj tento styl - NEMƒö≈á ho bƒõhem konverzace!",
        }

        # –û–ø–∏—Å–∞–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        corrections_descriptions = {
            "minimal": "Opravuj POUZE kritick√© chyby, kter√© V√ùRAZNƒö br√°n√≠ porozumƒõn√≠. "
                      "IGNORUJ: drobn√© gramatick√© chyby, chybƒõj√≠c√≠ ƒç√°rky, volbu slov (pokud je v√Ωznam jasn√Ω), "
                      "mal√© chyby v koncovk√°ch, pokud nebr√°n√≠ porozumƒõn√≠. "
                      "Opravuj POUZE: z√°sadn√≠ gramatick√© chyby, kter√© mƒõn√≠ v√Ωznam, "
                      "chyby v z√°kladn√≠ch slovech, kter√© br√°n√≠ porozumƒõn√≠ cel√© vƒõtƒõ. "
                      "D≈Øle≈æit√° je plynul√° konverzace, ne perfektn√≠ gramatika!",
            "balanced": "Opravuj d≈Øle≈æit√© chyby a obƒças vysvƒõtli pravidlo. "
                       "Balanc mezi uƒçen√≠m a konverzac√≠. Opravuj chyby, kter√© ovliv≈àuj√≠ v√Ωznam nebo jsou ƒçast√©.",
            "detailed": "Opravuj V≈†ECHNY chyby s podrobn√Ωmi vysvƒõtlen√≠mi gramatick√Ωch pravidel. "
                       "Pro pokroƒçil√© studenty hledaj√≠c√≠ perfekcionismus. "
                       "Vƒõnuj pozornost i drobn√Ωm chyb√°m v interpunkci a stylu.",
        }

        # –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–æ–¥–Ω–æ–≥–æ —è–∑—ã–∫–∞ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
        native_lang_names = {
            "ru": "ru≈°tina",
            "uk": "ukrajin≈°tina",
            "pl": "pol≈°tina",
            "sk": "sloven≈°tina",
        }
        native_lang_name = native_lang_names.get(native_language, "ru≈°tina")

        # ==========================================
        # COMPACT prompt for minimal/balanced (saves ~800 tokens ‚Üí 1-2 sec faster)
        # FULL prompt with grammar rules only for detailed corrections
        # ==========================================
        grammar_rules_block = ""
        if corrections_level == "detailed":
            grammar_rules_block = """
GRAMATICK√Å PRAVIDLA (Internetov√° jazykov√° p≈ô√≠ruƒçka √öJƒå):
Kdy≈æ student udƒõl√° chybu, odkazuj na konkr√©tn√≠ pravidla:
- Vyjmenovan√° slova (B, L, M, P, S, V, Z)
- Pravopis: bƒõ/bje, mƒõ/mnƒõ, √∫/≈Ø, i/y po obojetn√Ωch souhl√°sk√°ch
- Interpunkce: ƒç√°rky ve vedlej≈°√≠ch vƒõt√°ch, p≈ôed a/ale
- Velk√° p√≠smena: vlastn√≠ jm√©na, p≈ô√≠davn√° jm√©na od nich odvozen√°
- Tvaroslov√≠: sklo≈àov√°n√≠ podstatn√Ωch a p≈ô√≠davn√Ωch jmen, ƒçasov√°n√≠ sloves
- Skladba: slovosled, shoda p≈ô√≠sudku s podmƒõtem, p≈ôedlo≈æky s/z, v/na
Kdy≈æ je to relevantn√≠, zm√≠≈à mnemotechnickou pom≈Øcku nebo p≈ô√≠klad z p≈ô√≠ruƒçky.
"""

        base_prompt = f"""Ty jsi Honz√≠k - vesel√Ω ƒåech, kter√Ω pom√°h√° uƒçit se ƒçesky.
Jsi p≈ô√°telsk√Ω, vtipn√Ω, miluje≈° pivo üç∫, knedl√≠ky ü•ü a hokej üèí. Pou≈æ√≠v√°≈° v√Ωrazy jako Ahoj!, Nazdar!, V√Ωbornƒõ!

STUDENT: {level_descriptions[level]}
Styl: {style} | Opravy: {corrections_level} | Rodn√Ω jazyk: {native_lang_name}

STYL: {style_descriptions[style]}

OPRAVY: {corrections_descriptions[corrections_level]}
Vysvƒõtlen√≠ pi≈° JEDNODU≈†E ƒçesky na √∫rovni A2.
{grammar_rules_block}
√öKOL: Analyzuj text, oprav chyby, ohodno≈• 0-100, odpovƒõz p≈ôirozenƒõ jako Honz√≠k. Buƒè pozitivn√≠! Dodr≈æuj styl a slovn√≠ z√°sobu studenta.

ODPOVƒöZ JSON:
{{{{
  "honzik_response": "odpovƒõƒè Honz√≠ka v ƒçe≈°tinƒõ",
  "corrected_text": "opraven√Ω text studenta",
  "mistakes": [{{{{
    "original": "≈°patn√Ω text",
    "corrected": "spr√°vn√Ω text",
    "explanation_cs": "vysvƒõtlen√≠ ƒçesky max 15 slov"
  }}}}],
  "correctness_score": 85,
  "suggestion": "kr√°tk√Ω tip v jednoduch√© ƒçe≈°tinƒõ"
}}}}"""

        return base_prompt

    def _format_conversation_history(
        self, history: list[dict[str, str]]
    ) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

        Args:
            history: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π {"role": "user/assistant", "text": "..."}

        Returns:
            str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è
        """
        if not history:
            return "≈Ω√°dn√° p≈ôedchoz√≠ historie."

        formatted = []
        for msg in history[-5:]:  # –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
            role = "Student" if msg["role"] == "user" else "Honz√≠k"
            formatted.append(f"{role}: {msg['text']}")

        return "\n".join(formatted)

    async def generate_response(
        self,
        user_text: str,
        level: CzechLevel,
        style: ConversationStyle,
        corrections_level: CorrectionsLevel,
        native_language: NativeLanguage,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> dict:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –•–æ–Ω–∑–∏–∫–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ –∏ –æ—Ü–µ–Ω–∫–æ–π.

        Args:
            user_text: –¢–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —á–µ—à—Å–∫–æ–º
            level: –£—Ä–æ–≤–µ–Ω—å —á–µ—à—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
            style: –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è (friendly/tutor/casual)
            corrections_level: –£—Ä–æ–≤–µ–Ω—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π (minimal/balanced/detailed)
            native_language: –†–æ–¥–Ω–æ–π —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (ru/uk/pl/sk)
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π)

        Returns:
            dict: {
                "honzik_response": str,
                "corrected_text": str,
                "mistakes": list[dict],
                "correctness_score": int,
                "suggestion": str
            }

        Raises:
            ValueError: –ü—Ä–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º JSON –æ—Ç–≤–µ—Ç–µ –æ—Ç GPT
            APIError: –ü—Ä–∏ –æ—à–∏–±–∫–µ OpenAI API
        """
        self.logger.info(
            "generating_honzik_response",
            level=level,
            style=style,
            corrections_level=corrections_level,
            native_language=native_language,
            user_text_length=len(user_text),
        )

        if conversation_history is None:
            conversation_history = []

        # Cache ONLY the first greeting message (when there's no conversation history)
        # This saves API calls for the same initial greeting
        should_cache = len(conversation_history) == 0

        if should_cache:
            settings_dict = {
                "czech_level": level,
                "correction_level": corrections_level,
                "conversation_style": style,
                "native_language": native_language,
            }
            cached_response = await cache_service.get_cached_honzik_response(
                user_text, settings_dict
            )
            if cached_response:
                self.logger.info("using_cached_honzik_greeting")
                return cached_response

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        system_prompt = self._get_base_prompt(
            level=level,
            corrections_level=corrections_level,
            native_language=native_language,
            style=style,
        )

        # Only include history block when there's actual conversation history
        if conversation_history:
            history_text = self._format_conversation_history(conversation_history)
            user_prompt = (
                f"P≈ôepis studenta: {user_text}\n\n"
                f"Historie konverzace (posledn√≠ 5 zpr√°v):\n{history_text}\n\n"
                "Analyzuj text studenta a odpovƒõz ve form√°tu JSON podle instrukc√≠ v√Ω≈°e."
            )
        else:
            user_prompt = (
                f"P≈ôepis studenta: {user_text}\n\n"
                "Analyzuj text studenta a odpovƒõz ve form√°tu JSON podle instrukc√≠ v√Ω≈°e."
            )

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
        optimized_messages = self.openai_client.optimize_conversation_history(
            messages,
            max_tokens=2000,  # –†–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        )

        # –õ–æ–≥–∏—Ä—É–µ–º —ç–∫–æ–Ω–æ–º–∏—é —Ç–æ–∫–µ–Ω–æ–≤
        original_tokens = self.openai_client.estimate_messages_tokens(messages)
        optimized_tokens = self.openai_client.estimate_messages_tokens(optimized_messages)

        if original_tokens != optimized_tokens:
            self.logger.info(
                "tokens_optimized",
                original=original_tokens,
                optimized=optimized_tokens,
                saved=original_tokens - optimized_tokens,
            )

        # –í—ã–±–∏—Ä–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
        selected_model, model_reason = model_selector.select_model(
            user_text=user_text,
            czech_level=level,
            corrections_level=corrections_level,
            history_length=len(conversation_history),
        )

        self.logger.info(
            "model_selected_for_response",
            model=selected_model,
            reason=model_reason,
        )

        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –æ—Ç GPT –≤ JSON mode
            # max_tokens=400 prevents GPT from generating overly long responses
            # Typical Honz√≠k response is 150-300 tokens; 400 gives margin
            response_text = await self.openai_client.generate_chat_completion(
                messages=optimized_messages,
                json_mode=True,
                model=selected_model,
                max_tokens=400,
            )

            # –ü–∞—Ä—Å–∏–º JSON
            response_data = json.loads(response_text)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            required_fields = [
                "honzik_response",
                "corrected_text",
                "mistakes",
                "correctness_score",
                "suggestion",
            ]

            for field in required_fields:
                if field not in response_data:
                    self.logger.error(
                        "missing_field_in_response",
                        field=field,
                        response=response_data,
                    )
                    raise ValueError(f"Missing required field: {field}")

            # –í–∞–ª–∏–¥–∞—Ü–∏—è score
            score = response_data["correctness_score"]
            if not isinstance(score, (int, float)) or not (0 <= score <= 100):
                self.logger.warning(
                    "invalid_score",
                    score=score,
                )
                response_data["correctness_score"] = max(0, min(100, int(score)))

            # Fallback for corrected_text if None or empty
            if not response_data.get("corrected_text"):
                self.logger.warning(
                    "corrected_text_missing_using_original",
                    original_text=user_text[:50],
                )
                response_data["corrected_text"] = user_text

            self.logger.info(
                "honzik_response_generated",
                correctness_score=response_data["correctness_score"],
                mistakes_count=len(response_data["mistakes"]),
            )

            # Cache ONLY first greeting (no conversation history)
            if should_cache:
                await cache_service.cache_honzik_response(
                    user_text, settings_dict, response_data
                )
                self.logger.info("honzik_greeting_cached")

            return response_data

        except json.JSONDecodeError as e:
            self.logger.error(
                "json_decode_error",
                error=str(e),
                response_text=response_text[:200],
            )
            raise ValueError(f"Invalid JSON response from GPT: {e}")

        except Exception as e:
            self.logger.error(
                "honzik_response_failed",
                error=str(e),
            )
            raise

    def get_welcome_message(self) -> str:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –•–æ–Ω–∑–∏–∫–∞.

        –¢–µ–ø–µ—Ä—å –≤—Å–µ–≥–¥–∞ –Ω–∞ —á–µ—à—Å–∫–æ–º (Language Immersion).

        Returns:
            str: –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–µ—à—Å–∫–æ–º
        """
        return (
            "Ahoj! üá®üáø Jsem Honz√≠k - tv≈Øj vesel√Ω ƒçesk√Ω kamar√°d!\n\n"
            "Pomohu ti nauƒçit se ƒçesky p≈ôes ≈æivou konverzaci. "
            "Mluv se mnou ƒçesky a j√° tƒõ budu opravovat a podporovat!\n\n"
            "Miluji pivo üç∫, knedl√≠ky ü•ü, hokej üèí a Prahu ‚ù§Ô∏è\n\n"
            "Pojƒème procviƒçovat! Po≈°li mi hlasovou zpr√°vu v ƒçe≈°tinƒõ! üé§"
        )


